{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model for the signal peptide benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 10:04:24.494285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8354992609137938699\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 47581389312\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7266752102291184261\n",
      "physical_device_desc: \"device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:31:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 10:04:25.395252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 10:04:25.404123: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-19 10:04:25.404760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-05-19 10:04:26.697264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:31:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2023-05-19 10:04:26.697293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-19 10:04:26.923722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-19 10:04:26.923788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-05-19 10:04:27.021656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-19 10:04:27.213433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-19 10:04:27.396703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-05-19 10:04:27.492288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-05-19 10:04:28.031284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-19 10:04:28.031636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-05-19 10:04:28.031676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-19 10:10:36.031123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-19 10:10:36.031157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-05-19 10:10:36.031163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-05-19 10:10:36.031924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 45377 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:31:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 20:16:29.323389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train set length:  26088\n",
      "Validation set length:  3261\n",
      "Test set length:  3261\n",
      "Sequence length:  235\n",
      "Instance type:  <class 'numpy.str_'>\n",
      "Label type:  <class 'numpy.float64'>\n",
      "[2023_05_02-20:16:38] Training set: Filtered out 0 of 26088 (0.0%) records of lengths exceeding 235.\n",
      "[2023_05_02-20:16:38] Validation set: Filtered out 0 of 3261 (0.0%) records of lengths exceeding 235.\n",
      "[2023_05_02-20:16:38] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 20:16:38.865698: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-02 20:16:38.866580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-05-02 20:16:38.915951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:31:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2023-05-02 20:16:38.915981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-02 20:16:39.101435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-02 20:16:39.101551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-05-02 20:16:39.172832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-02 20:16:39.323011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-02 20:16:39.332650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-05-02 20:16:39.333383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-05-02 20:16:39.406403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-02 20:16:39.406862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-05-02 20:16:39.407338: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 20:16:39.411178: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-02 20:16:39.411484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:31:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2023-05-02 20:16:39.411515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-02 20:16:39.411536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-02 20:16:39.411545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-05-02 20:16:39.411553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-02 20:16:39.411562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-02 20:16:39.411570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-05-02 20:16:39.411579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-05-02 20:16:39.411588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-02 20:16:39.411758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-05-02 20:16:39.411788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-02 20:16:47.768723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-02 20:16:47.768751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-05-02 20:16:47.768759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-05-02 20:16:47.769328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 45377 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:31:00.0, compute capability: 8.6)\n",
      "2023-05-02 20:16:51.132695: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-05-02 20:16:51.144312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 20:16:55.972542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-02 20:16:57.754125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-02 20:17:05.931608: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cwise_op_gpu_base.cc:89 : Internal: Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n\t [[node model_2/global-attention-block1/Tanh (defined at home/jabarbero/anaconda3/envs/estancia/lib/python3.8/site-packages/proteinbert/conv_and_global_attention_model.py:72) ]] [Op:__inference_train_function_121579]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb Cell 3\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m model_generator \u001b[39m=\u001b[39m FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function \u001b[39m=\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m         get_model_with_hidden_layers_as_outputs, dropout_rate \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m training_callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(patience \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, factor \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m, min_lr \u001b[39m=\u001b[39m \u001b[39m1e-05\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, restore_best_weights \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m ]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set, train_labels, valid_set, valid_labels, \\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m         seq_len \u001b[39m=\u001b[39;49m seq_len\u001b[39m+\u001b[39;49m\u001b[39m2\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m, max_epochs_per_stage \u001b[39m=\u001b[39;49m \u001b[39m40\u001b[39;49m, lr \u001b[39m=\u001b[39;49m \u001b[39m1e-04\u001b[39;49m, begin_with_frozen_pretrained_layers \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m         lr_with_frozen_pretrained_layers \u001b[39m=\u001b[39;49m \u001b[39m1e-02\u001b[39;49m, n_final_epochs \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, final_seq_len \u001b[39m=\u001b[39;49m seq_len\u001b[39m+\u001b[39;49m\u001b[39m2\u001b[39;49m, final_lr \u001b[39m=\u001b[39;49m \u001b[39m1e-05\u001b[39;49m, callbacks \u001b[39m=\u001b[39;49m training_callbacks)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Evaluating the performance on the test-set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m results, confusion_matrix \u001b[39m=\u001b[39m evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set, test_labels, \\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/ProteinBERT/ProteinBERT_test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m         start_seq_len \u001b[39m=\u001b[39m seq_len, start_batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/proteinbert/finetuning.py:52\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m(model_generator, input_encoder, output_spec, train_seqs, train_raw_Y, valid_seqs, valid_raw_Y, seq_len, batch_size, max_epochs_per_stage, lr, begin_with_frozen_pretrained_layers, lr_with_frozen_pretrained_layers, n_final_epochs, final_seq_len, final_lr, callbacks)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m begin_with_frozen_pretrained_layers:\n\u001b[1;32m     51\u001b[0m     log(\u001b[39m'\u001b[39m\u001b[39mTraining with frozen pretrained layers...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m     model_generator\u001b[39m.\u001b[39;49mtrain(encoded_train_set, encoded_valid_set, seq_len, batch_size, max_epochs_per_stage, lr \u001b[39m=\u001b[39;49m lr_with_frozen_pretrained_layers, \\\n\u001b[1;32m     53\u001b[0m             callbacks \u001b[39m=\u001b[39;49m callbacks, freeze_pretrained_layers \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     55\u001b[0m log(\u001b[39m'\u001b[39m\u001b[39mTraining the entire fine-tuned model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m model_generator\u001b[39m.\u001b[39mtrain(encoded_train_set, encoded_valid_set, seq_len, batch_size, max_epochs_per_stage, lr \u001b[39m=\u001b[39m lr, callbacks \u001b[39m=\u001b[39m callbacks, \\\n\u001b[1;32m     57\u001b[0m         freeze_pretrained_layers \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/proteinbert/model_generation.py:29\u001b[0m, in \u001b[0;36mModelGenerator.train\u001b[0;34m(self, encoded_train_set, encoded_valid_set, seq_len, batch_size, n_epochs, lr, callbacks, **create_model_kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     model\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mlr \u001b[39m=\u001b[39m lr\n\u001b[0;32m---> 29\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_X, train_Y, sample_weight \u001b[39m=\u001b[39;49m train_sample_weigths, batch_size \u001b[39m=\u001b[39;49m batch_size, epochs \u001b[39m=\u001b[39;49m n_epochs, validation_data \u001b[39m=\u001b[39;49m encoded_valid_set, \\\n\u001b[1;32m     30\u001b[0m         callbacks \u001b[39m=\u001b[39;49m callbacks)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_state(model)\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    885\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    889\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[1;32m    891\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    892\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/estancia/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m:  Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n\t [[node model_2/global-attention-block1/Tanh (defined at home/jabarbero/anaconda3/envs/estancia/lib/python3.8/site-packages/proteinbert/conv_and_global_attention_model.py:72) ]] [Op:__inference_train_function_121579]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "OUTPUT_TYPE = OutputType(False, 'numeric')\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE)\n",
    "\n",
    "\n",
    "# Loading the dataset\n",
    "X_file = \"../../data/avgfp/avgfp_X.pkl\"\n",
    "y_file = \"../../data/avgfp/avgfp_y.pkl\"\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X = pkl.load(open(X_file, \"rb\"))\n",
    "y = pkl.load(open(y_file, \"rb\"))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Getting the length of the sequences\n",
    "seq_len = len(X[0])\n",
    "\n",
    "# Splitting the dataset into training, validation and test sets\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "valid_set, test_set, valid_labels, test_labels = train_test_split(test_set, test_labels, test_size = 0.5, random_state = 42)\n",
    "\n",
    "print(\"Train set length: \", len(train_set))\n",
    "print(\"Validation set length: \", len(valid_set))\n",
    "print(\"Test set length: \", len(test_set))\n",
    "print(\"Sequence length: \", seq_len)\n",
    "print(\"Instance type: \", type(train_set[0]))\n",
    "print(\"Label type: \", type(train_labels[0]))\n",
    "\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set, train_labels, valid_set, valid_labels, \\\n",
    "        seq_len = seq_len+2, batch_size = 32, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = seq_len+2, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "# Evaluating the performance on the test-set\n",
    "\n",
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set, test_labels, \\\n",
    "        start_seq_len = seq_len, start_batch_size = 32)\n",
    "\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len, log\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "BENCHMARKS = [\n",
    "    # name, output_type\n",
    "    ('signalP_binary', OutputType(False, 'binary')),\n",
    "    ('fluorescence', OutputType(False, 'numeric')),\n",
    "    ('remote_homology', OutputType(False, 'categorical')),\n",
    "    ('stability', OutputType(False, 'numeric')),\n",
    "    ('scop', OutputType(False, 'categorical')),\n",
    "    ('secondary_structure', OutputType(True, 'categorical')),\n",
    "    ('disorder_secondary_structure', OutputType(True, 'binary')),\n",
    "    ('ProFET_NP_SP_Cleaved', OutputType(False, 'binary')),\n",
    "    ('PhosphositePTM', OutputType(True, 'binary')),\n",
    "]\n",
    "\n",
    "settings = {\n",
    "    'max_dataset_size': None,\n",
    "    'max_epochs_per_stage': 40,\n",
    "    'seq_len': 512,\n",
    "    'batch_size': 32,\n",
    "    'final_epoch_seq_len': 1024,\n",
    "    'initial_lr_with_frozen_pretrained_layers': 1e-02,\n",
    "    'initial_lr_with_all_layers': 1e-04,\n",
    "    'final_epoch_lr': 1e-05,\n",
    "    'dropout_rate': 0.5,\n",
    "    'training_callbacks': [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "        keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "    ],\n",
    "}\n",
    "\n",
    "####### Uncomment for debug mode\n",
    "# settings['max_dataset_size'] = 500\n",
    "# settings['max_epochs_per_stage'] = 1\n",
    "\n",
    "def run_benchmark(benchmark_name, pretraining_model_generator, input_encoder, pretraining_model_manipulation_function = None):\n",
    "    \n",
    "    log('========== %s ==========' % benchmark_name)  \n",
    "    \n",
    "    output_type = get_benchmark_output_type(benchmark_name)\n",
    "    log('Output type: %s' % output_type)\n",
    "    \n",
    "    train_set, valid_set, test_set = load_benchmark_dataset(benchmark_name)        \n",
    "    log(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "    \n",
    "    if settings['max_dataset_size'] is not None:\n",
    "        log('Limiting the training, validation and test sets to %d records each.' % settings['max_dataset_size'])\n",
    "        train_set = train_set.sample(min(settings['max_dataset_size'], len(train_set)), random_state = 0)\n",
    "        valid_set = valid_set.sample(min(settings['max_dataset_size'], len(valid_set)), random_state = 0)\n",
    "        test_set = test_set.sample(min(settings['max_dataset_size'], len(test_set)), random_state = 0)\n",
    "    \n",
    "    if output_type.is_seq or output_type.is_categorical:\n",
    "        train_set['label'] = train_set['label'].astype(str)\n",
    "        valid_set['label'] = valid_set['label'].astype(str)\n",
    "        test_set['label'] = test_set['label'].astype(str)\n",
    "    else:\n",
    "        train_set['label'] = train_set['label'].astype(float)\n",
    "        valid_set['label'] = valid_set['label'].astype(float)\n",
    "        test_set['label'] = test_set['label'].astype(float)\n",
    "        \n",
    "    if output_type.is_categorical:\n",
    "        \n",
    "        if output_type.is_seq:\n",
    "            unique_labels = sorted(set.union(*train_set['label'].apply(set)) | set.union(*valid_set['label'].apply(set)) | \\\n",
    "                    set.union(*test_set['label'].apply(set)))\n",
    "        else:\n",
    "            unique_labels = sorted(set(train_set['label'].unique()) | set(valid_set['label'].unique()) | set(test_set['label'].unique()))\n",
    "            \n",
    "        log('%d unique lebels.' % len(unique_labels))\n",
    "    elif output_type.is_binary:\n",
    "        unique_labels = [0, 1]\n",
    "    else:\n",
    "        unique_labels = None\n",
    "        \n",
    "    output_spec = OutputSpec(output_type, unique_labels)\n",
    "    model_generator = FinetuningModelGenerator(pretraining_model_generator, output_spec, pretraining_model_manipulation_function = \\\n",
    "            pretraining_model_manipulation_function, dropout_rate = settings['dropout_rate'])\n",
    "    finetune(model_generator, input_encoder, output_spec, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "            seq_len = settings['seq_len'], batch_size = settings['batch_size'], max_epochs_per_stage = settings['max_epochs_per_stage'], \\\n",
    "            lr = settings['initial_lr_with_all_layers'], begin_with_frozen_pretrained_layers = True, lr_with_frozen_pretrained_layers = \\\n",
    "            settings['initial_lr_with_frozen_pretrained_layers'], n_final_epochs = 1, final_seq_len = settings['final_epoch_seq_len'], \\\n",
    "            final_lr = settings['final_epoch_lr'], callbacks = settings['training_callbacks'])\n",
    "    \n",
    "    for dataset_name, dataset in [('Training-set', train_set), ('Validation-set', valid_set), ('Test-set', test_set)]:\n",
    "        \n",
    "        log('*** %s performance: ***' % dataset_name)\n",
    "        results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, output_spec, dataset['seq'], dataset['label'], \\\n",
    "                start_seq_len = settings['seq_len'], start_batch_size = settings['batch_size'])\n",
    "    \n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(results)\n",
    "        \n",
    "        if confusion_matrix is not None:\n",
    "            with pd.option_context('display.max_rows', 16, 'display.max_columns', 10):\n",
    "                log('Confusion matrix:')\n",
    "                display(confusion_matrix)\n",
    "                \n",
    "    return model_generator\n",
    "\n",
    "def load_benchmark_dataset(benchmark_name):\n",
    "    \n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % benchmark_name)\n",
    "    valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.valid.csv' % benchmark_name)\n",
    "    test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % benchmark_name)\n",
    "    \n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "          \n",
    "    if os.path.exists(valid_set_file_path):\n",
    "        valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
    "    else:\n",
    "        log(f'Validation set {valid_set_file_path} missing. Splitting training set instead.')\n",
    "        train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "def get_benchmark_output_type(benchmark_name):\n",
    "    for name, output_type in BENCHMARKS:\n",
    "        if name == benchmark_name:\n",
    "            return output_type\n",
    "        \n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "for benchmark_name, _ in BENCHMARKS:\n",
    "    run_benchmark(benchmark_name, pretrained_model_generator, input_encoder, pretraining_model_manipulation_function = \\\n",
    "            get_model_with_hidden_layers_as_outputs)\n",
    "        \n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the attention layers\n",
    "\n",
    "You can run this only after you have fine-tuned the model on a benchmark (e.g. signal peptide) and obtained *model_generator*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BENCHMARK_DISPLAY_NAME = 'Signal peptide'\n",
    "\n",
    "TEST_SET_FILE_PATH = '/cs/phd/nadavb/my_public_ftp_site/protein_bert/protein_benchmarks/signalP_binary.train.csv'\n",
    "IDEAL_LEN = 80\n",
    "\n",
    "def calculate_attentions(model, input_encoder, seq, seq_len = None):\n",
    "    \n",
    "    from tensorflow.keras import backend as K\n",
    "    from proteinbert.tokenization import index_to_token\n",
    "    \n",
    "    if seq_len is None:\n",
    "        seq_len = len(seq) + 2\n",
    "    \n",
    "    X = input_encoder.encode_X([seq], seq_len)\n",
    "    (X_seq,), _ = X\n",
    "    seq_tokens = list(map(index_to_token.get, X_seq))\n",
    "\n",
    "    model_inputs = [layer.input for layer in model.layers if 'InputLayer' in str(type(layer))][::-1]\n",
    "    model_attentions = [layer.calculate_attention(layer.input) for layer in model.layers if 'GlobalAttention' in str(type(layer))]\n",
    "    invoke_model_attentions = K.function(model_inputs, model_attentions)\n",
    "    attention_values = invoke_model_attentions(X)\n",
    "    \n",
    "    attention_labels = []\n",
    "    merged_attention_values = []\n",
    "\n",
    "    for attention_layer_index, attention_layer_values in enumerate(attention_values):\n",
    "        for head_index, head_values in enumerate(attention_layer_values):\n",
    "            attention_labels.append('Attention %d - head %d' % (attention_layer_index + 1, head_index + 1))\n",
    "            merged_attention_values.append(head_values)\n",
    "\n",
    "    attention_values = np.array(merged_attention_values)\n",
    "    \n",
    "    return attention_values, seq_tokens, attention_labels\n",
    "\n",
    "def plot_attention(attention_values, seq_tokens, attention_labels, ax, cmap = 'Reds', vmin = 0, vmax = None, text_value_threshold = 0.1):\n",
    "\n",
    "    heatmap = ax.pcolor(attention_values.transpose(), cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(attention_labels)) + 0.5)\n",
    "    ax.set_xticklabels(attention_labels, rotation = 45, ha = 'right', fontsize = 12)\n",
    "    ax.set_yticks(np.arange(len(seq_tokens)) + 0.5)\n",
    "    ax.set_yticklabels(seq_tokens, fontsize = 12)\n",
    "\n",
    "    for i, row in enumerate(attention_values):\n",
    "        for j, value in enumerate(row):\n",
    "            if abs(value) >= text_value_threshold:\n",
    "                add_plus_sign = attention_values.min() < 0 and value > 0\n",
    "                plus_sign = '+' if add_plus_sign else ''\n",
    "                ax.text(i + 0.5, j + 0.5, plus_sign + '%d%%' % (100 * value), color = 'white', ha = 'center', va = 'center', \\\n",
    "                        fontsize = 9, fontweight = 'bold', fontstretch = 'condensed')\n",
    "                \n",
    "test_set = pd.read_csv(TEST_SET_FILE_PATH)\n",
    "chosen_index = ((test_set['seq'].str.len() - IDEAL_LEN).abs()).sort_values().index[0]\n",
    "seq = test_set.loc[chosen_index, 'seq']\n",
    "label = test_set.loc[chosen_index, 'label']\n",
    "                \n",
    "seq_len = len(seq) + 2\n",
    "\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "model = pretrained_model_generator.create_model(seq_len)\n",
    "pretrained_attention_values, pretrained_seq_tokens, pretrained_attention_labels = calculate_attentions(model, input_encoder, seq, \\\n",
    "        seq_len = seq_len)\n",
    "\n",
    "model = model_generator.create_model(seq_len)\n",
    "finetuned_attention_values, finetuned_seq_tokens, finetuned_attention_labels = calculate_attentions(model, input_encoder, seq, \\\n",
    "        seq_len = seq_len)\n",
    "assert finetuned_seq_tokens == pretrained_seq_tokens\n",
    "assert finetuned_attention_labels == pretrained_attention_labels[:len(finetuned_attention_labels)]\n",
    "\n",
    "fig, axes = plt.subplots(ncols = 4, figsize = (20, 0.2 * seq_len), gridspec_kw = dict(width_ratios = [1, 5, 1, 5]))\n",
    "fig.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "axes[0].barh(np.arange(seq_len), 100 * pretrained_attention_values.sum(axis = 0), color = '#EC7063')\n",
    "axes[0].set_ylim((-0.5, seq_len - 0.5))\n",
    "axes[0].set_yticks([])\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].set_xlabel('Total atten. %', fontsize = 14)\n",
    "\n",
    "vmax = pretrained_attention_values.max()\n",
    "plot_attention(pretrained_attention_values, pretrained_seq_tokens, pretrained_attention_labels, axes[1], cmap = 'Reds', vmax = vmax, \\\n",
    "        text_value_threshold = 0.05)\n",
    "axes[1].set_title('Only pre-training', fontsize = 16)\n",
    "\n",
    "axes[2].barh(np.arange(seq_len), 100 * (finetuned_attention_values - pretrained_attention_values).sum(axis = 0), color = '#28B463')\n",
    "axes[2].set_ylim((-0.5, seq_len - 0.5))\n",
    "axes[2].set_yticks([])\n",
    "axes[2].invert_xaxis()\n",
    "axes[2].set_xlabel('Total atten. % diff', fontsize = 14)\n",
    "\n",
    "attention_diff = finetuned_attention_values - pretrained_attention_values[:len(finetuned_attention_labels), :]\n",
    "vmax = np.abs(attention_diff).max()\n",
    "plot_attention(attention_diff, finetuned_seq_tokens, finetuned_attention_labels, axes[3], cmap = 'PiYG', vmin = -vmax, vmax = vmax, \\\n",
    "        text_value_threshold = 0.03)\n",
    "axes[3].set_title('%s fine-tuning' % BENCHMARK_DISPLAY_NAME, fontsize = 16)\n",
    "\n",
    "print(seq, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
