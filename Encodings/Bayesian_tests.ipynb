{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include sslearn folder\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os\n",
    "from SequenceEncoding import SequenceEncoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr, weightedtau\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import combinations, permutations\n",
    "from baycomp import two_on_multiple, HierarchicalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results\"\n",
    "encodings = [\"One_hot\", \"One_hot_6_bit\", \"Binary_5_bit\", \"Hydrophobicity_matrix\",\n",
    "             \"Meiler_parameters\", \"Acthely_factors\", \"PAM250\", \"BLOSUM62\",\n",
    "             \"Miyazawa_energies\", \"Micheletti_potentials\", \"AESNN3\",\n",
    "             \"ANN4D\"]\n",
    "masks = [\"relative\",\n",
    "        \"relativex2\",\n",
    "        \"relativex10\",\n",
    "        \"relativex0.5\",\n",
    "        \"relativex0.1\",\n",
    "        \"shannon\",\n",
    "        \"shannonx2\",\n",
    "        \"shannonx10\",\n",
    "        \"shannonx0.5\",\n",
    "        \"shannonx0.1\",\n",
    "        \"lockless\",\n",
    "        \"locklessx2\",\n",
    "        \"locklessx10\",\n",
    "        \"locklessx0.5\",\n",
    "        \"locklessx0.1\",\n",
    "        \"1-shannon\",\n",
    "        \"inverted_relative\",\n",
    "        \"inverted_shannon\",\n",
    "        \"inverted_lockless\",\n",
    "        \"normalized_relative\",\n",
    "        \"normalized_shannon\",\n",
    "        \"normalized_lockless\",\n",
    "        \"variants_emphasis_weight_0.25\",\n",
    "        \"variants_emphasis_weight_0.5\",\n",
    "        \"variants_emphasis_weight_0.75\",\n",
    "        \"variants_emphasis_weight_1.5\",\n",
    "        \"variants_emphasis_weight_2\",\n",
    "        \"variants_emphasis_weight_5\",\n",
    "        \"variants_gaussian_emphasis_weight_0.25\",\n",
    "        \"variants_gaussian_emphasis_weight_0.5\",\n",
    "        \"variants_gaussian_emphasis_weight_0.75\",\n",
    "        \"variants_gaussian_emphasis_weight_1.5\",\n",
    "        \"variants_gaussian_emphasis_weight_2\",\n",
    "        \"variants_gaussian_emphasis_weight_5\",\n",
    "        \"random\"]\n",
    "labeled_sizes_list = [1] #, 0.75, 0.5, 0.25, 0.1, 0.05, 0.03, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/masking_experiments_0.6M_BMIMI_Ridge/pred_dict_One_hot_masked_relative/2_1.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/Bayesian_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/Bayesian_tests.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m             global_pred_dict[enc][labeled_size] \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/Bayesian_tests.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mfor\u001b[39;00m mask \u001b[39min\u001b[39;00m masks:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/Bayesian_tests.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_results_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/pred_dict_\u001b[39;49m\u001b[39m{\u001b[39;49;00menc\u001b[39m}\u001b[39;49;00m\u001b[39m_masked_\u001b[39;49m\u001b[39m{\u001b[39;49;00mmask\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mlabeled_size\u001b[39m}\u001b[39;49;00m\u001b[39m.pickle\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/Bayesian_tests.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                 global_pred_dict[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00menc\u001b[39m}\u001b[39;00m\u001b[39m_masked_\u001b[39m\u001b[39m{\u001b[39;00mmask\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m][labeled_size] \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.168.168.50/home/jabarbero/MERGE/MultiencodingFitnessPrediction/Encodings/Bayesian_tests.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m encoding, labeled_sizes \u001b[39min\u001b[39;00m global_pred_dict\u001b[39m.\u001b[39mitems():\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/masking_experiments_0.6M_BMIMI_Ridge/pred_dict_One_hot_masked_relative/2_1.pickle'"
     ]
    }
   ],
   "source": [
    "experiments_type = \"masking_experiments\"\n",
    "# Create results dataframe\n",
    "df = pd.DataFrame(columns=['Dataset', 'Labeled', 'Train_size', 'Encoding', 'MSE', 'Spearman_r', 'Weighted_tau'])\n",
    "for dataset_results_folder in os.listdir(results_dir):\n",
    "    # Only the ones starting by mask\n",
    "    if dataset_results_folder.startswith(experiments_type):\n",
    "        # If is dir\n",
    "        if os.path.isdir(os.path.join(results_dir, dataset_results_folder)):    \n",
    "            global_pred_dict = dict()\n",
    "            dataset_results_dir = os.path.join(results_dir, dataset_results_folder)\n",
    "            dataset_name = \"_\".join(dataset_results_folder.split(experiments_type+\"_\")[1].split(\"_\")[:-1])\n",
    "            for enc in encodings:\n",
    "\n",
    "                global_pred_dict[enc] = dict()   \n",
    "                for mask in masks:\n",
    "                    global_pred_dict[f'{enc}_masked_{mask}'] = dict()\n",
    "\n",
    "                for labeled_size in labeled_sizes_list:\n",
    "                    with open(f'{dataset_results_dir}/pred_dict_{enc}_{labeled_size}.pickle', 'rb') as f:\n",
    "                        global_pred_dict[enc][labeled_size] = pkl.load(f)\n",
    "                    for mask in masks:\n",
    "                        with open(f'{dataset_results_dir}/pred_dict_{enc}_masked_{mask}_{labeled_size}.pickle', 'rb') as f:\n",
    "                            global_pred_dict[f'{enc}_masked_{mask}'][labeled_size] = pkl.load(f)\n",
    "\n",
    "            for encoding, labeled_sizes in global_pred_dict.items():\n",
    "                for labeled_size, folds in labeled_sizes.items():\n",
    "                    for fold, results in folds.items():\n",
    "                        y_proba = results[\"y_proba\"]\n",
    "                        y_test = results[\"original_y_test\"]\n",
    "                        train_size = results[\"train_len\"]\n",
    "                        mse = mean_squared_error(y_test, y_proba)\n",
    "                        rmse = np.sqrt(mse)\n",
    "                        spearman_r = spearmanr(y_test, y_proba)[0]\n",
    "\n",
    "                        weighted_tau = weightedtau(y_test, y_proba)[0]\n",
    "                        enc_value = encoding.split(\"_masked\")[0]        \n",
    "                        mask_value = encoding.split(\"_masked_\")[1] if \"masked\" in encoding else \"unmasked\"\n",
    "                        df = pd.concat([df, pd.DataFrame({'Dataset': dataset_name,\n",
    "                                                        'Labeled': labeled_size, \n",
    "                                                        'Train_size': train_size, \n",
    "                                                        'Encoding': enc_value,\n",
    "                                                        'Mask': mask_value,\n",
    "                                                        'MSE': mse, \n",
    "                                                        'RMSE': rmse,\n",
    "                                                        'Spearman_r': spearman_r,\n",
    "                                                        'Weighted_tau': weighted_tau\n",
    "                                                        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export df to csv\n",
    "df.to_csv(\"results/masking_experiments_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "df = pd.read_csv(\"results/masking_experiments_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baycomp_plotting import tern\n",
    "\n",
    "selected_metric = \"Spearman_r\"\n",
    "\n",
    "n_masks = len(df[\"Mask\"].unique().tolist())\n",
    "n_encodings = len(df[\"Encoding\"].unique().tolist())\n",
    "\n",
    "# Create a figure with masks x encodings\n",
    "for encoding in df[\"Encoding\"].unique().tolist():\n",
    "    # For every mask except unmasked\n",
    "    for mask in df[\"Mask\"].unique().tolist():\n",
    "\n",
    "        if mask != \"unmasked\":\n",
    "            \n",
    "            df_mask = df[(df[\"Labeled\"] == 1) & (df[\"Encoding\"] == encoding) & ((df[\"Mask\"] == \"unmasked\") | (df[\"Mask\"] == mask))]\n",
    "            df_mask = df_mask.groupby([\"Dataset\", \"Mask\"]).agg(list).reset_index()\n",
    "            \n",
    "            unmasked_matrix = np.array([np.array(x) for x in df_mask[df_mask[\"Mask\"] == \"unmasked\"][selected_metric].values]).T\n",
    "            masked_matrix = np.array([np.array(x) for x in df_mask[df_mask[\"Mask\"] == mask][selected_metric].values]).T\n",
    "            \n",
    "            posterior = HierarchicalTest(unmasked_matrix, masked_matrix, rope=0.01);\n",
    "            fig = tern(posterior, l_tag=\"unmasked\", r_tag=mask)\n",
    "            # Change title\n",
    "            fig.axes[0].set_title(f\"{encoding}\\n{mask}\", fontsize=50)\n",
    "            # Make figure bigger\n",
    "            fig.set_size_inches(12, 12)\n",
    "            # Put title closer to the plot\n",
    "            fig.subplots_adjust(top=0.85)\n",
    "            fig.savefig(\"results/figs/bayesian_\"+encoding+\"_\"+mask+\"_\"+selected_metric+\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def generateBigPlot(encodings, masks, metric_name, figs_dir): \n",
    "    \n",
    "    aux_img = cv2.imread(os.path.join(figs_dir, \"bayesian_\"+encodings[0]+\"_\"+masks[0]+\"_\"+metric_name+\".png\"))\n",
    "    aux_img[:] = (242, 242, 242)\n",
    "    \n",
    "    final = None \n",
    "    for idx, encoding in enumerate(encodings): \n",
    "        row = None \n",
    "        for idx2, mask in enumerate(masks): \n",
    "            \n",
    "            img = cv2.imread(os.path.join(figs_dir, \"bayesian_\"+encoding+\"_\"+mask+\"_\"+metric_name+\".png\"))\n",
    "                \n",
    "            if idx2==0: \n",
    "                row = img\n",
    "            else: \n",
    "                row = cv2.hconcat([row, img])\n",
    "                \n",
    "        if idx == 0: \n",
    "            final = row\n",
    "        else: \n",
    "            final = cv2.vconcat([final, row])\n",
    "            \n",
    "    cv2.imwrite(os.path.join(figs_dir, 'bayesian_comparative_'+metric_name+'.png'),final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateBigPlot(encodings, masks, \"Spearman_r\", \"results/figs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values for Labeled = 1, Encoding = One_hot\n",
    "df_one_hot = df[(df[\"Labeled\"] == 1) & (df[\"Encoding\"] == \"One_hot\") & ((df[\"Mask\"] == \"unmasked\") | (df[\"Mask\"] == \"normalized_relative\"))]\n",
    "df_one_hot.groupby([\"Dataset\", \"Mask\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best Spearman_r mean value for each dataset\n",
    "best_df = df.groupby([\"Dataset\", \"Mask\"]).mean()\n",
    "\n",
    "# Print the best mask for each dataset\n",
    "for dataset in best_df.index.get_level_values(0).unique().tolist():\n",
    "    print(dataset, best_df.loc[dataset].idxmax()[selected_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best Spearman_r mean value for each dataset\n",
    "best_df = df.groupby([\"Dataset\", \"Mask\"]).mean()\n",
    "\n",
    "# Print the best mask for each dataset\n",
    "for dataset in best_df.index.get_level_values(0).unique().tolist():\n",
    "    print(dataset, best_df.loc[dataset].idxmax()[selected_metric])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrapolation/generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_type = \"masking_extrapolation_experiments\"\n",
    "# Create results dataframe\n",
    "extrapolation_df = pd.DataFrame(columns=['Dataset', 'Labeled', 'Train_size', 'Encoding', 'MSE', 'Spearman_r', 'Weighted_tau'])\n",
    "for dataset_results_folder in os.listdir(results_dir):\n",
    "    # Only the ones starting by mask\n",
    "    if dataset_results_folder.startswith(experiments_type):\n",
    "        # If is dir\n",
    "        if os.path.isdir(os.path.join(results_dir, dataset_results_folder)):    \n",
    "            global_pred_dict = dict()\n",
    "            dataset_results_dir = os.path.join(results_dir, dataset_results_folder)\n",
    "            dataset_name = \"_\".join(dataset_results_folder.split(experiments_type+\"_\")[1].split(\"_\")[:-1])\n",
    "            for enc in encodings:\n",
    "\n",
    "                global_pred_dict[enc] = dict()   \n",
    "                for mask in masks:\n",
    "                    global_pred_dict[f'{enc}_masked_{mask}'] = dict()\n",
    "\n",
    "                for labeled_size in labeled_sizes_list:\n",
    "                    with open(f'{dataset_results_dir}/pred_dict_{enc}_{labeled_size}.pickle', 'rb') as f:\n",
    "                        global_pred_dict[enc][labeled_size] = pkl.load(f)\n",
    "                    for mask in masks:\n",
    "                        with open(f'{dataset_results_dir}/pred_dict_{enc}_masked_{mask}_{labeled_size}.pickle', 'rb') as f:\n",
    "                            global_pred_dict[f'{enc}_masked_{mask}'][labeled_size] = pkl.load(f)\n",
    "\n",
    "            for encoding, labeled_sizes in global_pred_dict.items():\n",
    "                for labeled_size, folds in labeled_sizes.items():\n",
    "                    for fold, results in folds.items():\n",
    "                        y_proba = results[\"y_proba\"]\n",
    "                        y_test = results[\"original_y_test\"]\n",
    "                        train_size = results[\"train_len\"]\n",
    "                        mse = mean_squared_error(y_test, y_proba)\n",
    "                        rmse = np.sqrt(mse)\n",
    "                        spearman_r = spearmanr(y_test, y_proba)[0]\n",
    "                        weighted_tau = weightedtau(y_test, y_proba)[0]\n",
    "                        enc_value = encoding.split(\"_masked\")[0]        \n",
    "                        mask_value = encoding.split(\"_masked_\")[1] if \"masked\" in encoding else \"unmasked\"\n",
    "                        extrapolation_df = pd.concat([extrapolation_df, pd.DataFrame({'Dataset': dataset_name,\n",
    "                                                        'Labeled': labeled_size, \n",
    "                                                        'Train_size': train_size, \n",
    "                                                        'Encoding': enc_value,\n",
    "                                                        'Mask': mask_value,\n",
    "                                                        'MSE': mse, \n",
    "                                                        'RMSE': rmse,\n",
    "                                                        'Spearman_r': spearman_r,\n",
    "                                                        'Weighted_tau': weighted_tau\n",
    "                                                        }, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrapolation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baycomp_plotting import tern\n",
    "\n",
    "# encodings = [\"One_hot\"]\n",
    "encodings = [\"One_hot\", \"One_hot_6_bit\", \"Binary_5_bit\", \"Hydrophobicity_matrix\",\n",
    "             \"Meiler_parameters\", \"Acthely_factors\", \"PAM250\", \"BLOSUM62\",\n",
    "             \"Miyazawa_energies\", \"Micheletti_potentials\", \"AESNN3\",\n",
    "             \"ANN4D\"]\n",
    "masks = [\"relative\", \"shannon\", \"lockless\", \"inverted_relative\", \"inverted_shannon\", \"inverted_lockless\", \"normalized_relative\", \"normalized_shannon\", \"normalized_lockless\", \"random\"]\n",
    "\n",
    "selected_metric = \"Spearman_r\"\n",
    "\n",
    "n_masks = len(df[\"Mask\"].unique().tolist())\n",
    "n_encodings = len(df[\"Encoding\"].unique().tolist())\n",
    "\n",
    "# Create a figure with masks x encodings\n",
    "for encoding in df[\"Encoding\"].unique().tolist():\n",
    "    # For every mask except unmasked\n",
    "    for mask in df[\"Mask\"].unique().tolist():\n",
    "\n",
    "        if mask != \"unmasked\":\n",
    "            \n",
    "            df_mask = df[(df[\"Labeled\"] == 1) & (df[\"Encoding\"] == encoding) & ((df[\"Mask\"] == \"unmasked\") | (df[\"Mask\"] == mask))]\n",
    "            df_mask = df_mask.groupby([\"Dataset\", \"Mask\"]).agg(list).reset_index()\n",
    "            \n",
    "            unmasked_matrix = np.array([np.array(x) for x in df_mask[df_mask[\"Mask\"] == \"unmasked\"][selected_metric].values]).T\n",
    "            masked_matrix = np.array([np.array(x) for x in df_mask[df_mask[\"Mask\"] == mask][selected_metric].values]).T\n",
    "            \n",
    "            posterior = HierarchicalTest(unmasked_matrix, masked_matrix, rope=0.01)\n",
    "            fig = tern(posterior, l_tag=\"unmasked\", r_tag=mask)\n",
    "            # Change title\n",
    "            fig.axes[0].set_title(f\"{encoding}\\n{mask}\", fontsize=50)\n",
    "            # Make figure bigger\n",
    "            fig.set_size_inches(12, 12)\n",
    "            # Put title closer to the plot\n",
    "            fig.subplots_adjust(top=0.85)\n",
    "            fig.savefig(\"results/figs/extrapolation/bayesian_\"+encoding+\"_\"+mask+\"_\"+selected_metric+\".png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f846180ea635b726345c5d1c5924730e4eae75f9c00483c60b47aa06388dcbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
